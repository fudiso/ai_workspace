# AI WorkSpace 추진 보고서
**AI솔루션본부**

## 1. 추진 개요
전사 임직원이 AI의 도움을 받아 데이터를 자유자재로 활용하는 'Data-Native' 조직으로의 전환을 목표로 함. 이를 위해 데이터 접근성을 극대화하고, 직무 및 역량 수준에 맞는 맞춤형 분석환경을 제공하고자 함. 

## 2. 프로젝트 목적
모든 임직원들이 데이터에 자유롭게 접근하고, 직관적인 인터페이스와 AI 기술을 활용하여 스스로 데이터를 찾아 분석하며, 반복적인 업무를 자동화할 수 있는 통합 환경을 구축하는 것을 목적으로 함. 이를 통해 데이터 기반의 신속하고 정교한 의사결정을 지원하고, 전사적인 업무 효율성과 생산성을 극대화하고자 함.

## 3. 현황 및 문제점
핵심 운용부서에서는 필요한 데이터를 사내 DB에서 찾기 보다 블룸버그나 Factset등 고비용의 외부 정보 단말에 크게 의존하고 있음. 이는 내부 데이터의 존재를 모르거나, 접근 권한의 부재에서 기인함.
또한 데이터 분석 요청이 IT 부서나 소수의 데이터 전문가에게 집중되면서 업무 속도와 대응력에 병목이 발생하고 있으며, Excel 기반의 수작업 방식은 복잡한 금융 분석과 대용량 데이터 처리에서 정확성과 확장성의 한계를 드러내고 있음.
일반 업무 담당자들은 Python 등 분석 도구에 대한 심리적/기술적 장벽으로 활용하지 못하고, 일부 적극적으로 활용하는 부서들도 개발된 분석 로직이나 노하우가 개인이나 부서 차원에 머물러 조직전체의 자산으로 축적되지 못하고 있음. 또한, 우수한 분석 결과가 지속적인 의사결정 시스템과 유기적으로 연결되지 못해 실질적 활용성이 떨어지고 있음.

### 문제점 요약

| 문제 영역 | 주요 이슈 요약 |
|-----------|----------------|
| IT 지원 업무 병목 | 데이터 관련 요청이 IT/전문 인력에 집중되어 대응 지연 발생 |
| 데이터 접근성 취약 | 필요 데이터의 소재를 모르거나, 접근 권한이 없어 고비용 단말에 의존 |
| 분석 환경 한계 | 기존 Excel 중심 도구는 복잡한 금융 분석 및 확장성 한계 |
| 기술 진입 장벽 | Python 등 전문 분석 도구에 대한 심리적·기술적 부담 |
| 지식 자산의 사일로화 | 분석 노하우가 부서별 고립(사일로화)되어 중복 발생 및 자산축적 안됨 |
| 자동화 미비 | 수작업 기반의 반복 업무로 인해 업무 효율성이 낮음 |
| 협업 어려움 | 데이터 권한 및 형식의 분절화로 부서 간 통합 분석 및 협업 어려움 |

## 4. AI WorkSpace(가칭) 솔루션
"데이터를 찾기 어렵고, 분석 역량은 제한적이고, 노하우가 축적되지 못하는" 구조적 문제를 해결하기 위해, 데이터 민주화 플랫폼을 지향하는 AI WorkSpace 프로젝트를 추진하고자 함. AI WorkSpace는 정형 및 반정형데이터의 탐색과 활용에 중점을 두며, Microsoft Copilot이 담당할 비정형 문서 데이터 영역과 함께 전사적인 AI기반 데이터 활용 생태계를 완성하고자 함.

필요한 데이터를 사내에서 찾지 못해 외부 정보 단말기에 의존하던 문제를 해결하기 위해 AI WorkSpace는 강력한 '데이터 디스커버리 플랫폼(Data Discovery Platform)'의 역할을 수행. AI의 도움으로 내부 데이터를 쉽게 찾아 활용하는 새로운 업무방식을 제시하며, 그 핵심 구성요소와 작동 방식은 다음과 같음.

**[그림1: AI WorkSpace 핵심 구성 요소]**

### 4.1 핵심 구성요소

#### 1) 데이터 카탈로그 (Data Catalog)
- 전사에 공유 가능한 데이터를 한곳에 모아 데이터 사일로를 해소하고, 사용자가 필요한 데이터를 탐색할 수 있는 기반을 마련
- 이를 통해 외부 단말기에서 데이터를 다운로드하는 번거로움을 줄이고, 검증된 내부 데이터 활용 촉진

#### 2) 코드 카탈로그 (Code Catalog)
- 업무 프로세스와 데이터 분석 노하우를 코드로 자산화하여 체계적으로 축적하고 관리함
- 부서별 유사업무의 중복 수행 문제를 해결하고 분석의 효율성과 일관성을 높임

#### 3) LLM기반 AI 어시스턴트
- 자연어로 질의하면 AI어시스턴트가 Python코드나 SQL쿼리로 자동 변환하여 데이터를 조회
- 코드에 대한 기술적 장벽을 낮추는 역할을 함

#### 4) 클라우드 IDE 및 실행환경
- 웹 브라우저를 통해 바로 접속할 수 있는 코드 실행 및 개발환경
- AI어시스턴트를 통해 생성했거나 코드 카탈로그에서 가져온 코드를 바로 실행 가능
- 개인이 직접 개발환경을 구성할 필요가 없음

#### 5) 워크플로우 자동화
- 코드 카탈로그에 등록된 코드를 워크플로우 자동화 툴과 연계하여 반복적으로 수행가능

## 5. 구축 전략
AI WorkSpace는 오픈소스 기반의 맞춤형 구축을 통해 비용 효율성과 기술적 유연성을 확보하면서, 단계적 검증과 조직내 자산화 문화의 정착을 함께 추구하는 전략을 설정.

### 5.1 오픈소스 기반 맞춤형 구축
- 상용 AI플랫폼(Palantir, Dataiku 등) 대비 낮은 비용과 높은 유연성, 그리고 조직의 역량 강화 측면에서 자체 구축 전략을 가져감
- 데이터 카탈로그내의 메타정보 관리 프레임워크로 Palantir의 온톨로지 개념을 일부 내재화 가능할 것으로 판단됨
- 오픈소스 도입의 기술적 장벽을 낮추기 위해 전문 기술업체 및 웹 개발 파트너와 협업하여 핵심기능을 빠르게 구현, 안정적인 운영을 추구

### 5.2 핵심 구성 요소별 전략
- **데이터 카탈로그**: Snowflake를 기반으로 사내외 데이터 통합하여 데이터 접근 단일 창구 마련. 전문 업체 컨설팅을 통한 데이터 디스커버리 툴(DataHub등) 도입
- **코드 카탈로그**: 검증된 분석 로직과 코드를 '코드 카탈로그'에 자산화하여 전사적으로 재사용하고, GitLab을 통해 체계적으로 버전 관리
- **LLM기반 AI 어시스턴트**: 내부 질의 엔진 개발(OpenAI API, MCP활용)
- **클라우드 IDE 및 실행환경**: VS Code Server, JupyterHub 활용
- **워크플로우 자동화**: n8n 또는 Apache Airflow 검토, Teams/이메일 연동
- **웹 포탈**: "AI WorkSpace 웹 포탈" 제공. 웹 개발 업체와의 계약을 통해 진행할 계획임

### 5.3 변화관리 전략 및 조직내 역할 재정의
- "일반 사용자 → 분석자산 소비자 → 생산자 (파워유저) → 전문가"로의 사용자 진화 여정 설계. 그에 맞는 기능, 교육, 커뮤니티 제공
- 초기 IT부서를 중심으로 재사용 가능한 분석자산 (조회화면, 코드 컴포넌트)의 생산자의 역할 필요
- AI솔루션본부는 지속적인 플랫폼 기능개선, 사용자 피드백 수집 및 반영, 금융 특화 AI 모델 큐레이션 등 AI WorkSpace 운영중심 조직으로 기능 확장

### 5.4 지속 가능한 운영 및 거버넌스
- 고품질의 데이터, 분석 코드, 자동화 플로우를 중앙 저장소에 등록하고 공유함으로써 조직의 분석 자산을 체계적으로 관리. 자산 품질관리를 위한 체계 필요
- 단계별 캠페인, 핵심사용자 발굴, 부서장 대상 워크숍등 커뮤니케이션 전략을 통해 사내 인식 전환 및 지지 기반 확보
- 플랫폼 효과를 정기적으로 경영진에 리포팅하고, 전사 전략과 연계된 성과를 통해 지속적 지원 확보

## 참고 1. 추진 일정

| 단계 | 기간 | 주요 진행사항 | 목표 |
|------|------|---------------|------|
| 1단계 | 1-3개월 | **핵심 데이터 접근성 확보**<br/>• Snowflake 기반 데이터 인프라 연동<br/>• LLM 기반 자연어 조회 API 핵심 기능 프로토타입 개발 | 가장 시급한 '데이터 조회' 문제를 해결하여 빠른 성공 경험(Quick-Win)을 제공하고 프로젝트 지지자 확보 |
| 2단계 | 4-6개월 | **분석 자산화 및 환경 제공**<br/>• 데이터/코드 카탈로그 시스템 구축<br/>• Power User를 위한 클라우드 기반 코드 실행 환경 제공 | 고품질 데이터와 코드의 재사용성을 높이고, 심화 분석이 가능한 기반 마련 |
| 3단계 | 7-12개월 | **현업 적용 및 피드백 기반 고도화**<br/>• 운용, 리스크 등 핵심 부서 대상 시범 운영<br/>• 워크플로우 자동화 툴(n8n 등) 도입 및 연계<br/>• 사용자 교육 | 실제 업무에 적용하며 사용성을 검증하고, 업무 자동화를 통해 체감 효용성 극대화 |
| 4단계 | 12개월- | **전사 확대 및 문화 내재화**<br/>• 전사 부서를 대상으로 플랫폼 확대 적용<br/>• 우수 활용 사례 발굴 및 공유를 통한 조직 문화 내재화 | AI WorkSpace 활용을 전사적인 업무 방식으로 정착 |

## 참고 2. 사용자 시나리오

### 시나리오 1: [대체솔루션운용본부] 데일리 자료 작성
1. **(문제 상황)** 소O익 매니저는 매일 아침 KFP의 여러 화면을 일일이 클릭하여 데이터를 다운로드하고, 블룸버그 엑셀 파일을 Reloading 하는 등 데일리 자료를 작성하는데 5분-30분 소요됨.
2. **(데이터 질의)** 포털에 접속해서 "특정 펀드의 최근 포지션 현황과 헤지비율 데이터를 보여줘"라고 입력. 시스템이 KFP 데이터가 저장된 Snowflake에서 해당 정보를 조회하는 SQL 쿼리와 Python 코드를 자동 생성.
3. **(데이터 확보 및 코드 수정)** AI 클라우드 IDE 환경에서 제시된 코드를 수행해 보고, AI의 도움을 받아 Bloomberg API를 통해 추가데이터를 가져와 통합 분석 로직 추가
4. **(코드 카탈로그 공유)** 완성된 분석 코드를 "펀드 데일리 보고서 자동생성"이라는 이름으로 코드 카탈로그에 업로드하고 대체솔루션운용본부 팀원들과 공유
5. **(워크플로우 자동화)** 검증된 코드를 자동화 프로세스에 등록하여 매일 오전 8시에 자동 실행되도록 설정. 코드 실행 → 엑셀 파일 생성 → 관련자들에게 팀즈 메신저 또는 메일 발송 자동화

### 시나리오 2: [연금전략본부] 기관 투자자 맞춤형 포트폴리오
1. **(문제 상황)** A 운용역은 특정 연기금으로부터 '기존 글로벌 성장주 펀드에서 ESG 점수가 낮은 기업을 제외하고, 반도체 섹터 비중을 20%로 늘려달라'는 맞춤형 포트폴리오 요청을 받음.
2. **(데이터 및 로직 확보)** A 운용역은 AI WorkSpace 포털에 접속하여 **'코드 카탈로그'**에서 '글로벌 성장주 펀드 구성' 코드를 불러옴. 이 코드는 내부 펀드 정보 시스템(DB)에서 포트폴리오 구성 정보를 가져오는 기능을 포함하고 있음.
3. **(코드 수정 및 백테스트)** A 운용역은 AI Code Assistant(Cursor)에게 “ESG 점수 데이터베이스를 참조하여, 'B' 등급 이하인 종목은 제외해줘.”와 같은 자연어 질의를 통해 코드를 수정
4. **(결과 확인 및 저장)** 클라우드 IDE 실행 환경에서 AI에 의해 수정된 코드를 수행후 결과 확인. 수정된 포트폴리오가 검증되면 ‘A연기금 맞춤형 성장주 포트 생성’이름으로 '코드 카탈로그'에 저장하여 자산화

### 시나리오 3: [리스크관리부서] 이벤트 기반 리스크 현황 분석
1. **(이슈 발생)** '미 연준, 금리 0.5% 전격 인상'이라는 뉴스를 보고 B 리스크 매니저는 금리 변동에 민감한 자산을 보유한 펀드 리스트를 파악하고자 함.
2. **(자연어 질의)** B 매니저는 LLM 채팅창에 "현재 운용 중인 모든 펀드 중에서, 듀레이션이 5년 이상인 채권 보유 비중이 10% 이상인 펀드 리스트와 해당 채권의 상세 정보를 알려줘"라고 입력.
3. **(결과 분석)** 시스템은 내부 펀드 정보 DB와 채권 정보 DB를 동시에 조회하여 해당 펀드 목록과 관련 데이터를 즉시 테이블 형태로 제공.
4. **(Copilot 연동)** B 매니저는 펀드 목록 및 관련데이터를 Copilot에 제시하고 "이 펀드들의 운용역에게 즉시 Teams로 알림 메시지를 보내줘"라고 지시하여 신속한 초동 대응을 수행

### 시나리오 4: [마케팅부서] 콘텐츠 등록 및 AI 검색엔진 연동 자동화
1. **(콘텐츠 작성)** 마케팅부서 C매니저는 '2025년 펀드 상품 분석' 유튜브 영상을 제작하고 홈페이지에 소개하고자 함. AI검색엔진에서 효과적으로 해당 컨텐츠를 제공하기 위해 동영상 스크립트 및 홈페이지 URL을 C매니저가 수작업으로 업로드 해야 했음.
2. **(자동화 실행)** C 매니저는 AI WorkSpace포털에서 “유튜브 영상 연계 자동화” 워크플로우를 실행하고, URL 정보를 입력.
3. **(프로세스 자동화)** 워크플로우 툴에서는 입력된 URL에서 영상제목, 설명, 자막(스크립트) 정보를 자동으로 추출, LLM엔진으로 추출된 스크립트를 분석 AI검색엔진 최적화 형태로 변환, 구조화된 정보를 DB에 저장하는 작업을 수행
4. **(AI검색 연동)** 고객이 홈페이지에서 ‘2025년 펀드’라고 검색하면 AI검색 엔진이 새롭게 올린 유튜브 영상 소개 URL을 상위에 제시

### 시나리오 5: [IT-현업 협업] 핵심 기능의 'Code Component' 제공
1. **(IT 부서의 역할 변화)** IT 부서는 기존 펀드 성과분석 시스템의 '기여도 분석' 기능을 현업에서 직접 활용할 수 있도록 '코드 카탈로그'에 패키지 형태로 제공. 이 패키지에는 '성과분석 함수'와 필요한 '데이터 명세(펀드 코드, 기준일 등)'가 함께 포함되어 있음.
2. **(현업의 주도적 분석)** 운용역은 이 코드를 자신의 분석 환경으로 가져와, 특정 펀드와 기간을 입력하여 직접 성과 기여도 분석을 수행.
3. **(자체적 확장)** 더 나아가, 운용역은 AI Code Assistant의 도움을 받아 기존 코드에 '특정 섹터별 기여도'를 추가로 분석하는 로직을 덧붙여 자신만의 분석 툴로 발전. IT 부서에 별도의 개발을 요청하고 기다릴 필요 없이, 현업이 직접 필요한 기능을 즉시 구현하고 활용
4. **(부서내 공유)** 수정한 로직을 팀내에서 활용할 수 있도록 ‘코드 카탈로그’에 업로드

